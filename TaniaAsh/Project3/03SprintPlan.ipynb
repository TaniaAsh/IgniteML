{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–ª–∞–Ω —Ä–∞–±–æ—Ç—ã –Ω–∞ –≤—Ç–æ—Ä–æ–π —Å–ø—Ä–∏–Ω—Ç (25/01/25-07/02/25)\n",
    "**–ú–æ–¥–µ–ª—å:** –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –†–µ–≥—Ä–µ—Å—Å–∏—è  \n",
    "**–î–∞—Ç–∞—Å–µ—Ç:** [Titanic](https://www.kaggle.com/datasets/yasserh/titanic-dataset)\n",
    "\n",
    "1. **–ü—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ**  \n",
    "   –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞, –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å –∏—Ö –≤ DataFrame.   \n",
    "\n",
    "2. **–ò–∑—É—á–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç**  \n",
    "   - –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫.  \n",
    "   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å .info(), .describe(), .head() –∏ –¥—Ä. –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –∏ —Ç–∏–ø–æ–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.  \n",
    "   -–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –ø–∞—Ä—É –≥—Ä–∞—Ñ–∏–∫–æ–≤. –°–∫–∞–∂–µ–º, –æ—Ü–µ–Ω–∏—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö, –Ω–∞–ø—Ä–∏–º–µ—Ä –≤–æ–∑—Ä–∞—Å—Ç–∞. –ò–ª–∏ –ø–æ–∫–∞–∑–∞—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –º–µ–∂–¥—É –∫–ª—é—á–µ–≤—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (–¥–ª—è –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏—è  —Å–º–æ—Ç—Ä–∏ appendix).\n",
    "\n",
    "3. **–ü–æ—á–∏—Å—Ç–∏—Ç—å –¥–∞–Ω–Ω—ã–µ**  \n",
    "   - –û—Ü–µ–Ω–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (.isnull().sum()).\n",
    "   - –ï—Å–ª–∏ –Ω—É–∂–Ω–æ, –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏—Ö:\n",
    "   - –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫/—Å—Ç–æ–ª–±—Ü–æ–≤ —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–æ–ø—É—Å–∫–æ–≤.\n",
    "   - (*) –ò–ª–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –º–µ–¥–∏–∞–Ω–æ–π, —Å—Ä–µ–¥–Ω–∏–º, –º–æ–¥–æ–π.  \n",
    "   - (**) –ó–∞–º–µ–Ω–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–º–∏ (–µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ). –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ –ø–∏—Ç–æ–Ω–∞ –∏–ª–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É—è OneHotEncoder  \n",
    "   - (***) –ü—Ä–∏–º–µ–Ω–∏—Ç—å StandardScaler –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n",
    "\n",
    "4. **–°–æ–∑–¥–∞—Ç—å –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å**  \n",
    "   - –í—ã–±—Ä–∞—Ç—å –≤—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (X) –∏ —Ü–µ–ª–µ–≤–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä (y). \n",
    "   - –†–∞–∑–¥–µ–ª–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –∏ —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä—ã.\n",
    "   - –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ X –∏ y.  \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# üìù –ó–∞–¥–∞–Ω–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–π –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ (MLP) –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ä—É–∫–æ–ø–∏—Å–Ω—ã—Ö —Ü–∏—Ñ—Ä\n",
    "\n",
    "## **–û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞–Ω–∏—è**\n",
    "–í —ç—Ç–æ–º –∑–∞–¥–∞–Ω–∏–∏ –≤–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç –ø–æ—Å—Ç—Ä–æ–∏—Ç—å **–ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—É—é –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å (MLP)** –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ä—É–∫–æ–ø–∏—Å–Ω—ã—Ö —Ü–∏—Ñ—Ä –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ **MNIST**.\n",
    "\n",
    "### **–ß—Ç–æ –≤—ã –∏–∑—É—á–∏—Ç–µ?**\n",
    "- –ö–∞–∫ –∑–∞–≥—Ä—É–∂–∞—Ç—å –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ MNIST.\n",
    "- –ö–∞–∫ —Å—Ç—Ä–æ–∏—Ç—å –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω—É—é –Ω–µ–π—Ä–æ—Å–µ—Ç—å –Ω–∞ Keras.\n",
    "- –ö–∞–∫ –æ–±—É—á–∞—Ç—å –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å.\n",
    "- –ö–∞–∫ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–±–æ—Ç—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–∏.\n",
    "- –ö–∞–∫ –∏–∑–º–µ–Ω—è—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏ –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –µ—ë –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.\n",
    "\n",
    "## **–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑–∞–¥–∞–Ω–∏—è**\n",
    "1. **–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö** MNIST.\n",
    "2. **–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞** (–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è, one-hot encoding).\n",
    "3. **–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏** (–ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å Keras).\n",
    "4. **–ò–∑–º–µ–Ω–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏** (–¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Å–ª–æ–µ–≤, –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –Ω–µ–π—Ä–æ–Ω–æ–≤).\n",
    "5. **–ü–æ–¥–±–æ—Ä –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ø–æ—Ö** (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —ç–ø–æ—Ö –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è).\n",
    "6. **–ê–Ω–∞–ª–∏–∑ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏** –∏ **–ø–æ–∏—Å–∫ —Ü–∏—Ñ—Ä—ã —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º–∏ –∏ –Ω–∞–∏–º–µ–Ω—å—à–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏**.\n",
    "7. **–†–∞–∑–±–æ—Ä —Ç–µ—Ä–º–∏–Ω–æ–≤** (adam, categorical_crossentropy, bias, loss function, softmax).\n",
    "8. **–ü–æ–ø—ã—Ç–∫–∞ –æ–±—ä—è—Å–Ω–∏—Ç—å, —á—Ç–æ —Ç–∞–∫–æ–µ –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω** –æ–∫—Ä—É–∂–∞—é—â–∏–º.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# üìå –®–∞–≥ 1: –ò–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "# üìå –®–∞–≥ 2: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö MNIST\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# üìå –®–∞–≥ 3: –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (0-255 ‚Üí 0-1)\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# One-hot encoding –º–µ—Ç–æ–∫ –∫–ª–∞—Å—Å–æ–≤\n",
    "y_train_cat = keras.utils.to_categorical(y_train, 10)\n",
    "y_test_cat = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# üìå –®–∞–≥ 4: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–≤—ã—Ö 25 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "\n",
    "# üìå –®–∞–≥ 5: –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ MLP\n",
    "model = keras.Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# –í—ã–≤–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏\n",
    "print(model.summary())\n",
    "\n",
    "# üìå –®–∞–≥ 6: –ò–∑–º–µ–Ω–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏\n",
    "# üõ†Ô∏è **–ó–∞–¥–∞–Ω–∏–µ**: –î–æ–±–∞–≤—å—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–∏ –∏–ª–∏ –∏–∑–º–µ–Ω–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–π—Ä–æ–Ω–æ–≤ –≤ —Å–∫—Ä—ã—Ç–æ–º —Å–ª–æ–µ.\n",
    "# –ü—Ä–∏–º–µ—Ä: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤—Ç–æ—Ä–æ–≥–æ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è\n",
    "model = keras.Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "print(model.summary())\n",
    "\n",
    "# üìå –®–∞–≥ 7: –ü–æ–¥–±–æ—Ä –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ø–æ—Ö\n",
    "# üõ†Ô∏è **–ó–∞–¥–∞–Ω–∏–µ**: –ò–∑–º–µ–Ω–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è –∏ –Ω–∞–π–¥–∏—Ç–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ.\n",
    "epochs_list = [5, 10, 20]\n",
    "results = {}\n",
    "\n",
    "for epochs in epochs_list:\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train_cat, batch_size=32, epochs=epochs, validation_split=0.2)\n",
    "    loss, accuracy = model.evaluate(x_test, y_test_cat)\n",
    "    results[epochs] = accuracy\n",
    "\n",
    "# üìå –®–∞–≥ 8: –ê–Ω–∞–ª–∏–∑ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏\n",
    "print(\"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–∑–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ø–æ—Ö:\")\n",
    "for epochs, acc in results.items():\n",
    "    print(f\"–≠–ø–æ—Ö–∏: {epochs}, –¢–æ—á–Ω–æ—Å—Ç—å: {acc:.4f}\")\n",
    "\n",
    "# üìå –®–∞–≥ 9: –ü–æ–∏—Å–∫ —Ü–∏—Ñ—Ä—ã —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º–∏ –∏ –Ω–∞–∏–º–µ–Ω—å—à–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏\n",
    "predictions = model.predict(x_test)\n",
    "pred_labels = np.argmax(predictions, axis=1)\n",
    "incorrect = pred_labels != y_test\n",
    "\n",
    "unique, counts = np.unique(y_test[incorrect], return_counts=True)\n",
    "error_analysis = dict(zip(unique, counts))\n",
    "most_errors = max(error_analysis, key=error_analysis.get)\n",
    "least_errors = min(error_analysis, key=error_analysis.get)\n",
    "\n",
    "print(f'–ë–æ–ª—å—à–µ –≤—Å–µ–≥–æ –æ—à–∏–±–æ–∫ –Ω–∞ —Ü–∏—Ñ—Ä–µ: {most_errors}')\n",
    "print(f'–ú–µ–Ω—å—à–µ –≤—Å–µ–≥–æ –æ—à–∏–±–æ–∫ –Ω–∞ —Ü–∏—Ñ—Ä–µ: {least_errors}')\n",
    "\n",
    "# üìå –®–∞–≥ 10: –†–∞–∑–±–æ—Ä —Ç–µ—Ä–º–∏–Ω–æ–≤\n",
    "terms = {\n",
    "    \"Adam\": \"–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä, –∞–¥–∞–ø—Ç–∏–≤–Ω–æ –∏–∑–º–µ–Ω—è—é—â–∏–π —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è.\",\n",
    "    \"categorical_crossentropy\": \"–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –¥–ª—è –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.\",\n",
    "    \"bias\": \"–°–º–µ—â–µ–Ω–∏–µ (b) –≤ –Ω–µ–π—Ä–æ–Ω–µ, –ø–æ–º–æ–≥–∞–µ—Ç —Å–¥–≤–∏–≥–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –∞–∫—Ç–∏–≤–∞—Ü–∏–∏.\",\n",
    "    \"loss function\": \"–§—É–Ω–∫—Ü–∏—è, –æ–ø—Ä–µ–¥–µ–ª—è—é—â–∞—è —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º –∏ –∏—Å—Ç–∏–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏.\",\n",
    "    \"softmax\": \"–ê–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –ø—Ä–µ–≤—Ä–∞—â–∞—é—â–∞—è –≤—ã—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏.\"\n",
    "}\n",
    "for term, definition in terms.items():\n",
    "    print(f\"{term}: {definition}\")\n",
    "\n",
    "# üìå –®–∞–≥ 11: –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω–∞\n",
    "# üõ†Ô∏è **–ó–∞–¥–∞–Ω–∏–µ**: –ù–∞–π–¥–∏—Ç–µ –∫–æ–≥–æ-—Ç–æ, –∫—Ç–æ –Ω–µ –∑–Ω–∞–∫–æ–º —Å –Ω–µ–π—Ä–æ—Å–µ—Ç—è–º–∏, –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–±—ä—è—Å–Ω–∏—Ç—å –µ–º—É, —á—Ç–æ —Ç–∞–∫–æ–µ –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω. –ù–∞–ø–∏—à–∏—Ç–µ, –∫–∞–∫ —ç—Ç–æ –ø—Ä–æ—à–ª–æ.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
