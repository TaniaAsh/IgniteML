{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# План работы: Классификация заболеваний кожи на основе датасета Dermatology Dataset Classification\n",
    "\n",
    "## 1. Постановка задачи\n",
    "\n",
    "### 1.1 Описание проблемы\n",
    "Цель проекта – построить и протестировать несколько моделей машинного обучения для классификации заболеваний кожи на основе датасета [Dermatology Dataset Classification](https://www.kaggle.com/datasets/olcaybolat1/dermatology-dataset-classification/data).\n",
    "\n",
    "### 1.2 Описание данных\n",
    "Датасет содержит информацию о различных типах заболеваний кожи с соответствующими характеристиками. Основные признаки представлены числовыми данными, а целевая переменная – категориальная.\n",
    "\n",
    "## 2. Подготовка данных\n",
    "\n",
    "### 2.1 Загрузка данных\n",
    "- Загрузка датасета с Kaggle.\n",
    "- Первичный анализ данных (размер, типы данных, наличие пропущенных значений).\n",
    "\n",
    "### 2.2 Предобработка данных\n",
    "- Обработка пропущенных значений (замена медианой, средним или удаление).\n",
    "- Кодирование категориальных признаков (если есть).\n",
    "- Масштабирование числовых признаков (MinMaxScaler, StandardScaler) *.\n",
    "- Разделение данных на обучающий и тестовый набор (train/test split).\n",
    "\n",
    "## 3. Разработка и тестирование моделей\n",
    "\n",
    "### 3.1 Базовые модели\n",
    "- Простая нейронная сеть (однослойный персептрон).\n",
    "- Сложная нейронная сеть (многослойный персептрон MLP).\n",
    "- Логистическая регрессия.\n",
    "- Дерево решений.\n",
    "- Случайный лес (Random Forest).\n",
    "\n",
    "### 3.2 Пример кода: Decision Tree и Random Forest\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Разделение данных на train и test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Дерево решений\n",
    "dt_clf = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "dt_preds = dt_clf.predict(X_test)\n",
    "print(f\"Decision Tree Accuracy: {accuracy_score(y_test, dt_preds):.4f}\")\n",
    "\n",
    "# Случайный лес\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_preds = rf_clf.predict(X_test)\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_test, rf_preds):.4f}\")\n",
    "```\n",
    "\n",
    "### 3.3 Настройка гиперпараметров *\n",
    "Для каждой модели провести эксперименты с разными гиперпараметрами:\n",
    "- **Персептрон**: количество нейронов, функции активации.\n",
    "- **Логистическая регрессия**: метод оптимизации.\n",
    "- **Дерево решений**: глубина (`max_depth`), критерий (`gini` или `entropy`).\n",
    "- **Случайный лес**: количество деревьев (`n_estimators`), глубина (`max_depth`).\n",
    "\n",
    "### 3.4 GridSearchCV для подбора гиперпараметров **\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 20]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best accuracy: {grid_search.best_score_:.4f}\")\n",
    "```\n",
    "\n",
    "### 3.5 Оценка качества моделей\n",
    "Для каждой модели провести несколько итераций обучения с разными гиперпараметрами и оценить точность на тестовом наборе данных. Метрики:\n",
    "- **Accuracy**\n",
    "- **Precision, Recall, F1-score**\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "```\n",
    "\n",
    "## 4. Анализ результатов\n",
    "- Сравнение всех моделей по основным метрикам.\n",
    "- Визуализация результатов.\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "## 5. Выводы и рекомендации\n",
    "- Какая модель показала лучшие результаты?\n",
    "- Какие гиперпараметры оказались наиболее значимыми?\n",
    "- Возможные улучшения.\n",
    "\n",
    "## 6. Дальнейшие шаги **\n",
    "- Провести дополнительное тестирование на вводимых пользователем данных (опросник)**.\n",
    "- Автоматизировать процесс поиска гиперпараметров **.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
